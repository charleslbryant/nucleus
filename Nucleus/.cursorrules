# Nucleus Project Intelligence

## Project Overview
Nucleus is an ASP.NET Core application that provides observability and evaluation for AI-enabled automation workflows. It integrates with n8n, Make, and Power Automate to automatically evaluate AI outputs and trigger human feedback when needed.

## Core Functionality
- **Single API Endpoint**: `/api/evaluate` for all workflow platforms
- **LLM Evaluation**: OpenAI GPT integration for automatic scoring (0-5 scale)
- **Database Schema**: Three core tables (workflow_run, model_run, evaluation)
- **Human Feedback**: Trigger notifications when score < 3.5 threshold
- **Multi-Platform Support**: n8n, Make, Power Automate integration

## Architecture Patterns
- **Clean Architecture**: Dependencies point inward toward Domain layer (see [architecture.md](docs/architecture.md))
- **Strategy Pattern**: Different evaluator types (LLM, human, rule)
- **Repository Pattern**: Data access abstraction for PostgreSQL
- **Dependency Injection**: Loose coupling between layers

## Technology Stack
- ASP.NET Core with Entity Framework Core
- PostgreSQL with JSONB for flexible data storage
- OpenAI GPT API for LLM evaluation
- JWT authentication (for dashboard access)
- FluentValidation and AutoMapper

## Database Schema
- **workflow_run**: Tracks workflow executions with external IDs
- **model_run**: Records AI model executions with input/output data
- **evaluation**: Stores evaluation results with scores and feedback

## Development Guidelines
- Always maintain layer separation (Domain → Application → Interface/Infrastructure)
- Use UUID primary keys with external reference fields
- Implement proper validation for API inputs
- Handle OpenAI API rate limits and errors
- Use JSONB for flexible payload storage
- Follow the single endpoint design pattern

## File Organization
- **Domain**: Core entities (workflow_run, model_run, evaluation)
- **Application**: Evaluation use cases, LLM integration, orchestration
- **Interface**: `/api/evaluate` controller, DTOs, validation
- **Infrastructure**: PostgreSQL context, OpenAI API integration

## Common Patterns
- Use strategy pattern for different evaluator types
- Implement repository interfaces in Domain layer
- Use DTOs for API communication with external platforms
- Apply validation at Interface layer with FluentValidation
- Use AutoMapper for object mapping between layers

## Integration Patterns
- **n8n**: HTTP Request Node with JSON templates
- **Make**: HTTP webhook integration
- **Power Automate**: HTTP trigger integration
- **OpenAI**: HTTP client with retry logic and rate limiting

## Testing Strategy
- Unit tests for Domain and Application layers
- Integration tests for Infrastructure layer (database, OpenAI API)
- API tests for `/api/evaluate` endpoint
- Mock external dependencies (OpenAI API, workflow platforms)

## Memory Bank
- Always read memory bank files at start of each session
- Update documentation after significant changes
- Use memory bank for context and decision tracking
- Follow the three-phase roadmap (Foundation → Integration → Observability)

# Database Connection String Rule
- Never write database connection strings to appsettings.json or appsettings.Development.json.
- Always keep connection strings in a .env file.
- Copy C:\Users\charl\source\repos\workos\Nucleus\.env.example to any project that needs a connection string.

# Terminal Command Rules
- NEVER use && in terminal commands due to shell compatibility issues
- Use separate commands or semicolons (;) instead of &&
- Always run commands one at a time to avoid shell parsing issues
- Use proper directory navigation with cd commands separately

# Product Management Process for Nucleus

## Artifacts
- **PRDs (Product Requirement Documents):** Define feature requirements, user problems, jobs-to-be-done, and user journeys. One PRD per feature, stored in `docs/roadmap/product-requirements/`.
- **Roadmap:** Prioritizes PRDs into Now, Next, and Future buckets. Single file in `docs/roadmap/roadmap.md`.
- **CRDs (Change Request Documents):** Break down "Now" PRDs into actionable tasks for implementation. One CRD per active PRD, stored in `docs/roadmap/change-requests/`.
- **Task Logs:** Daily logs of all tasks, grouped by status (in progress, on hold, to do, done, cancelled), stored in `docs/tasks/`.

## Workflow
1. **Session Start:**
   - Review the memory bank.
   - Review the roadmap, current PRD(s), CRDs for active PRDs, and today's task log.
   - If no task log for today, copy the last log to today.
   - Determine the next task with the operator.
   - Create a plan in chat.
2. **Execution:**
   - Work with the operator to execute the plan, updating task log, CRD, and PRD as needed.
3. **Recap (on completion or request):**
   - Review what was done in the session.
   - Update task log, CRD, and PRD as necessary.
   - Stage changes (git add), check status, write commit message, commit, push, and create a pull request.

## Principles
- All requirements and tasks are traceable from PRD → CRD → Task Log.
- Only PRDs in the "Now" bucket get CRDs and active tasks.
- All changes are documented and linked for full traceability.
- The .cursorrules file is updated as the process evolves. 