# AI Agent Platform

# SAMUS: Designing a Semantic Kernel Clone of Manus and ANUS AI Agents

## Introduction

Manus AI and its open-source counterpart ANUS AI represent a new generation of autonomous AI agents that can plan and execute complex tasks with minimal human intervention. Manus, developed by the Chinese startup Monica, is touted as the world’s first fully autonomous AI agent, capable of *turning your thoughts into actions* by planning multi-step workflows and carrying them out asynchronously in the cloud ([*Overview of MANUS AI Agent. Company Background and Project Overview \| by Astropomeai \| Mar, 2025 \| Medium*](https://medium.com/@astropomeai/overview-of-manus-ai-agent-6b1f37d90a91#:~:text=The%20MANUS%20project%20was%20officially,Deep%20Research)) ([*Manus AI - China's Fully Autonomous AI Agent*](https://opencv.org/blog/manus-ai/#:~:text=Artificial%20Intelligence%20,making%20processes)). ANUS (Autonomous Networked Utility System) is an open-source framework created to mimic Manus’s capabilities, providing a community-driven implementation of a general AI agent ([*GitHub - nikmcfly/ANUS*](https://github.com/nikmcfly/ANUS#:~:text=Introduction)) ([*GitHub - nikmcfly/ANUS*](https://github.com/nikmcfly/ANUS#:~:text=Anus%20empowers%20users%20to%20create,AI%20agents%20that%20can)). The goal of the SAMUS project is to combine the strengths of Manus and ANUS into a C\# implementation using Microsoft’s Semantic Kernel, delivering a **multi-agent AI system** optimized for cloud deployment in an AI consulting agency setting. This report provides a deep analysis of the Manus and ANUS architectures, outlines how their components map to Semantic Kernel concepts, and offers guidance for building and deploying the SAMUS framework, along with potential enhancements for real-world consulting use cases.

## Background: Manus AI and ANUS AI Agent Frameworks

### Manus AI: Architecture and Capabilities

Manus AI is a **fully autonomous AI agent** distinguished by its ability to independently plan, execute, and complete tasks across various domains ([*Manus AI - China's Fully Autonomous AI Agent*](https://opencv.org/blog/manus-ai/#:~:text=1)) ([*Overview of MANUS AI Agent. Company Background and Project Overview \| by Astropomeai \| Mar, 2025 \| Medium*](https://medium.com/@astropomeai/overview-of-manus-ai-agent-6b1f37d90a91#:~:text=MANUS%20supports%20multimodal%20interactions%2C%20processing,to%20improve%20future%20task%20performance)). Unlike traditional chatbots that only respond to queries, Manus operates more like an AI **“executive assistant”**, taking high-level goals from the user and performing all necessary steps to achieve them ([*Manus AI - China's Fully Autonomous AI Agent*](https://opencv.org/blog/manus-ai/#:~:text=Manus%20AI%20is%20a%20sophisticated,making%20processes%20and%20creative%20execution)) ([*Overview of MANUS AI Agent. Company Background and Project Overview \| by Astropomeai \| Mar, 2025 \| Medium*](https://medium.com/@astropomeai/overview-of-manus-ai-agent-6b1f37d90a91#:~:text=Features%20and%20Capabilities%20of%20the,AI%20Agent)). Some key capabilities and features of Manus include:

-   **Multi-Agent Architecture:** Manus uses a *multi-agent (multi-module) design* where a central orchestrator (the “brain”) coordinates several specialized sub-agents or modules working in parallel ([*In-depth technical investigation into the Manus AI agent, focusing on its architecture, tool orchestration, and autonomous capabilities. · GitHub*](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=%28Manus%E5%9C%A8%E7%B4%85%E4%BB%80%E9%BA%BC%EF%BC%9F%E5%A4%96%E5%AA%92%E8%A9%95%E6%B8%AC%E8%A8%82%E9%A4%90%E3%80%81%E8%A8%82%E4%BD%8D%E3%80%81%E8%A8%82%E7%A5%A8%E2%8B%AF%E9%83%BD%E7%A2%B0%E5%A3%81%EF%BC%9A%E5%AE%83%E6%98%AF%E4%B8%AD%E5%9C%8B%E7%AC%AC%E4%BA%8C%E5%80%8BDeepSeek%E6%99%82%E5%88%BB%EF%BC%9F%29.%20A%20high,one%20agent%20writing%20the%20code)) ([*In-depth technical investigation into the Manus AI agent, focusing on its architecture, tool orchestration, and autonomous capabilities. · GitHub*](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=another%20agent%20spinning%20up%20a,happens%20within%20Manus%E2%80%99s%20system%20architecture)). Rather than a single monolithic model, Manus is structured so that different agents handle different aspects of a complex task – for example, one sub-agent focuses on web research, another writes code, while another analyzes data ([*In-depth technical investigation into the Manus AI agent, focusing on its architecture, tool orchestration, and autonomous capabilities. · GitHub*](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=components%20can%20work%20in%20parallel,is%20inspired%20by%20distributed%20problem)) ([*In-depth technical investigation into the Manus AI agent, focusing on its architecture, tool orchestration, and autonomous capabilities. · GitHub*](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=this%20multi,handling%20the%20whole%20project%20seamlessly)). The main Manus agent divides the task among these specialists and then integrates their results. This distributed design enables Manus to tackle multifaceted projects more efficiently and produce tangible outputs (like a formatted Excel report or a deployed website) that would require many steps and skills if done sequentially ([*In-depth technical investigation into the Manus AI agent, focusing on its architecture, tool orchestration, and autonomous capabilities. · GitHub*](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=faceted%20projects%20more%20efficiently,From)) ([*In-depth technical investigation into the Manus AI agent, focusing on its architecture, tool orchestration, and autonomous capabilities. · GitHub*](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=this%20multi,handling%20the%20whole%20project%20seamlessly)). From the user’s perspective, however, all this complexity is hidden behind a single interface – Manus appears as one AI assistant that “gets everything done while you rest” ([*Manus AI*](https://manus.im/#:~:text=Manus%20AI%20Manus%20is%20a,everything%20done%20while%20you%20rest)).

\- **Iterative Planning and Tool Use Loop:** Under the hood, Manus operates via an iterative agent loop of **“analyze → plan → execute → observe (and iterate)”** ([*In-depth technical investigation into the Manus AI agent, focusing on its architecture, tool orchestration, and autonomous capabilities. · GitHub*](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=virtual%20computing%20environment%20with%20full,Playwright%20for%20web%20interaction%2C%20and)). In each cycle, Manus analyzes the current goal and context, plans the next action, executes that action (often by invoking an external tool or running code), then observes the result and adjusts its plan ([*In-depth technical investigation into the Manus AI agent, focusing on its architecture, tool orchestration, and autonomous capabilities. · GitHub*](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=virtual%20computing%20environment%20with%20full,Playwright%20for%20web%20interaction%2C%20and)). This continues until the overall task is completed. Each sub-agent or module follows a similar loop for its specific subtask, with the central agent orchestrating their interactions. This structured workflow was observed by early researchers dissecting Manus’s behavior ([*Manus AI: Features, Architecture, Access, Early Issues & More \| DataCamp*](https://www.datacamp.com/blog/manus-ai#:~:text=Multi)) ([*Manus AI: Features, Architecture, Access, Early Issues & More \| DataCamp*](https://www.datacamp.com/blog/manus-ai#:~:text=a%20Linux%20sandbox,further%20user%20input%20is%20required)). In fact, Manus’s loop can be summarized in steps: **1)** analyze user request and state, **2)** select an appropriate tool or API for the next step, **3)** execute the command (e.g. run a script or perform web automation) in a sandbox, **4)** observe results and iterate, **5)** compile and return the results, and **6)** remain on standby for further input ([*Manus AI: Features, Architecture, Access, Early Issues & More \| DataCamp*](https://www.datacamp.com/blog/manus-ai#:~:text=Based%20on%20initial%20discoveries%20by,Each%20session%20follows%20this%20process)) ([*Manus AI: Features, Architecture, Access, Early Issues & More \| DataCamp*](https://www.datacamp.com/blog/manus-ai#:~:text=the%20task%20is%20completed,further%20user%20input%20is%20required)).

-   **Powerful Tool Integration (Sandboxed Execution):** A hallmark of Manus is its ability to interact with a wide range of external tools and systems, all within a controlled cloud-based environment. Manus runs in a *virtual Ubuntu Linux workspace (sandbox)* on the cloud servers, which means it has an OS-level environment to perform operations just like a human user on a computer ([*In-depth technical investigation into the Manus AI agent, focusing on its architecture, tool orchestration, and autonomous capabilities. · GitHub*](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=Cloud%20Agent%20with%20Tool%20Sandbox%3A,All%20of%20this%20happens%20server)). Within this sandbox, Manus has access to:
    -   A **Linux shell with sudo privileges** – it can execute command-line operations, install software, manage files, and run scripts ([*In-depth technical investigation into the Manus AI agent, focusing on its architecture, tool orchestration, and autonomous capabilities. · GitHub*](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=Cloud%20Agent%20with%20Tool%20Sandbox%3A,All%20of%20this%20happens%20server)).

        \- A **web browser interface** – Manus can control a browser to navigate websites, perform searches, scrape data, and even execute JavaScript in pages ([*Manus AI: Features, Architecture, Access, Early Issues & More \| DataCamp*](https://www.datacamp.com/blog/manus-ai#:~:text=,based%20workflows)) ([*In-depth technical investigation into the Manus AI agent, focusing on its architecture, tool orchestration, and autonomous capabilities. · GitHub*](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=full%20Ubuntu%20Linux%20workspace%20with,for%20example%2C%20OpenAI%E2%80%99s)).

    -   **Programming language interpreters** – it can write and run code (e.g. Python, Node.js) to use libraries or call APIs. Instead of being limited to a fixed set of hardcoded tools, Manus often generates and executes code on the fly to perform actions (a strategy known as the “CodeAct” paradigm) ([*In-depth technical investigation into the Manus AI agent, focusing on its architecture, tool orchestration, and autonomous capabilities. · GitHub*](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=Executable%20Code%20Actions%20,one%20go%2C%20handle%20conditional%20flows)) ([*In-depth technical investigation into the Manus AI agent, focusing on its architecture, tool orchestration, and autonomous capabilities. · GitHub*](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=and%20make%20use%20of%20countless,The%20sandbox)). For example, if asked to fetch weather data, Manus might dynamically write a short Python script to call a weather API and parse the response ([*In-depth technical investigation into the Manus AI agent, focusing on its architecture, tool orchestration, and autonomous capabilities. · GitHub*](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=tokens%20like%20%E2%80%9CSEARCH,Elicit%20Better%20LLM%20Agents)) ([*In-depth technical investigation into the Manus AI agent, focusing on its architecture, tool orchestration, and autonomous capabilities. · GitHub*](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=OpenReview%20openreview,to%20iteratively%20write%2C%20execute%2C%20and)). This ability to write code as actions gives Manus tremendous flexibility – it can combine logic, call multiple APIs, and handle conditionals in one go, then debug and adjust the code in subsequent iterations based on the observed output ([*In-depth technical investigation into the Manus AI agent, focusing on its architecture, tool orchestration, and autonomous capabilities. · GitHub*](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=%E2%80%93%20the%20model%E2%80%99s%20%E2%80%9Cacts%E2%80%9D%20are,Python%20code%20that%20calls%20the)) ([*In-depth technical investigation into the Manus AI agent, focusing on its architecture, tool orchestration, and autonomous capabilities. · GitHub*](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=OpenReview%20openreview,to%20iteratively%20write%2C%20execute%2C%20and)).

        \- **File system access** – Manus can read and write files within its sandbox, enabling it to generate reports, save intermediate data, or modify documents as needed ([*Manus AI: Features, Architecture, Access, Early Issues & More \| DataCamp*](https://www.datacamp.com/blog/manus-ai#:~:text=%2A%20Shell%20and%20command,hosting%20services%20on%20public%20URLs)).

    -   **Networking and servers** – Manus is even capable of launching web servers or web services from the sandbox and exposing them (e.g., to deploy an app or a dashboard it created) ([*In-depth technical investigation into the Manus AI agent, focusing on its architecture, tool orchestration, and autonomous capabilities. · GitHub*](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=full%20Ubuntu%20Linux%20workspace%20with,for%20example%2C%20OpenAI%E2%80%99s)). All these operations happen server-side; importantly, Manus continues working on tasks asynchronously even if the user goes offline or closes their browser ([*Overview of MANUS AI Agent. Company Background and Project Overview \| by Astropomeai \| Mar, 2025 \| Medium*](https://medium.com/@astropomeai/overview-of-manus-ai-agent-6b1f37d90a91#:~:text=MANUS%20supports%20multimodal%20interactions%2C%20processing,to%20improve%20future%20task%20performance)) ([*Introducing Manus: The general AI agent — WorkOS*](https://workos.com/blog/introducing-manus-the-general-ai-agent#:~:text=Manus%20operates%20within%20a%20virtual,sending%20notifications%20when%20it%20finishes)).

        *Security:* These powerful integrations are safeguarded by sandboxing. Manus’s design emphasizes that all potentially risky actions (code execution, web access, etc.) occur in an isolated virtual environment with controlled permissions ([*Overview of MANUS AI Agent. Company Background and Project Overview \| by Astropomeai \| Mar, 2025 \| Medium*](https://medium.com/@astropomeai/overview-of-manus-ai-agent-6b1f37d90a91#:~:text=executable%20code,to%20improve%20future%20task%20performance)) ([*Manus AI: Features, Architecture, Access, Early Issues & More \| DataCamp*](https://www.datacamp.com/blog/manus-ai#:~:text=Manus%20AI%27s%20core%20architectural%20features,These%20features%20include)). This mitigates the risk of an autonomous agent causing harm to the host system or beyond. For example, Manus can manipulate files in its virtual machine, but it shouldn’t have access to the user’s local filesystem or unauthorized external systems. (In practice, early critics noted concerns about how secure the sandbox is – more on this in a later section on improvements.)

\- **Multi-Modal Input/Output:** Manus is designed to handle various data formats. It can process textual information, analyze images, interpret tables or spreadsheets, and even handle executable code as both input and output ([*Overview of MANUS AI Agent. Company Background and Project Overview \| by Astropomeai \| Mar, 2025 \| Medium*](https://medium.com/@astropomeai/overview-of-manus-ai-agent-6b1f37d90a91#:~:text=MANUS%20supports%20multimodal%20interactions%2C%20processing,to%20improve%20future%20task%20performance)) ([*Manus AI: The Best Autonomous AI Agent Redefining Automation and Productivity*](https://huggingface.co/blog/LLMhacker/manus-ai-best-ai-agent#:~:text=Manus%20AI%20is%20a%20next,a%20truly%20autonomous%20AI%20agent)). In use cases, this means Manus can do things like read a PDF or image (using OCR or vision tools) as part of understanding a task, or produce an output that includes visual elements (charts, images) and working code. For instance, one public demo showed Manus generating a financial analysis dashboard (including charts and tables) and deploying it to a website automatically ([*Manus AI: Features, Architecture, Access, Early Issues & More \| DataCamp*](https://www.datacamp.com/blog/manus-ai#:~:text=For%20instance%2C%20it%20can%20start,prompts%2C%20like%20in%20this%20example)) ([*Manus AI: Features, Architecture, Access, Early Issues & More \| DataCamp*](https://www.datacamp.com/blog/manus-ai#:~:text=Source%3A%20Manus%20AI)). This multi-modality is key for consulting scenarios where tasks might involve mixing text (reports), data (spreadsheets), and visuals (slides or graphs).

\- **Memory and Learning:** Manus maintains both short-term and long-term memory of interactions. In the short term, it keeps track of the conversation or task context so it knows what steps have been taken and what the user’s request is. It uses a file-based memory or internal knowledge base to log progress and results of subtasks ([*In-depth technical investigation into the Manus AI agent, focusing on its architecture, tool orchestration, and autonomous capabilities. · GitHub*](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=Python%20code%20as%20its%20action,performance%20will%20require%20careful%20prompt)) ([*In-depth technical investigation into the Manus AI agent, focusing on its architecture, tool orchestration, and autonomous capabilities. · GitHub*](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=agent%20loop%20,prompt%20engineering%20and%20extensive%20testing)). This means if the agent is working on a lengthy project (say a market research report), it doesn’t forget earlier findings when moving to later steps. Manus also remembers user preferences and past instructions across sessions, allowing it to personalize its approach over time ([*Overview of MANUS AI Agent. Company Background and Project Overview \| by Astropomeai \| Mar, 2025 \| Medium*](https://medium.com/@astropomeai/overview-of-manus-ai-agent-6b1f37d90a91#:~:text=executable%20code,to%20improve%20future%20task%20performance)). For example, if a user previously indicated a preference (such as favoring certain data sources or a writing style), Manus can recall that in future tasks. This persistent memory is critical for an agent in a consulting role, since it enables continuity and cumulative learning across engagements.

\- **Foundation Models and “Multi-Model” Orchestration:** Rather than relying on a single AI model, Manus leverages **multiple underlying LLMs** to power its intelligence. Reports indicate that Manus initially used *Anthropic’s Claude 3.5 (codename “Sonnet v1”)* as the core reasoning engine, along with fine-tuned versions of Alibaba’s Qwen model ([*In-depth technical investigation into the Manus AI agent, focusing on its architecture, tool orchestration, and autonomous capabilities. · GitHub*](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=Foundation%20Model%20Backbone%3A%20Manus%20is,AI_%E6%96%B0%E6%B5%AA%E7%A7%91%E6%8A%80_%E6%96%B0%E6%B5%AA%E7%BD%91%29.%20Reports%20indicate)). Moreover, Manus can dynamically invoke different models for different subtasks – e.g. using **Claude** for complex reasoning, **GPT-4** for coding, or **Google Gemini** for broad knowledge queries ([*In-depth technical investigation into the Manus AI agent, focusing on its architecture, tool orchestration, and autonomous capabilities. · GitHub*](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=Manus%20can%20even%20invoke%20multiple,tier%20LLMs%2C%20rather%20than)) ([*Inside Manus: The Anatomy of an Autonomous AI Agent \| by Jalaj Agrawal \| Mar, 2025 \| Medium*](https://medium.com/@jalajagr/inside-manus-the-anatomy-of-an-autonomous-ai-agent-b3042e5e5084#:~:text=What%E2%80%99s%20particularly%20interesting%20is%20that,For%20example)). This multi-model strategy allows Manus to play to each model’s strengths, essentially using the best tool (model) for each job. Such an approach is beneficial in a consulting context: for instance, a code-generation task might be handed to a code-specialized LLM, while a data summary might use a model known for concise explanations. Manus orchestrates these models behind the scenes, so the user just sees coherent results. This design also means Manus is not tied to one provider; it can integrate new models as they become available, keeping it at the cutting edge of AI capabilities.

-   **Performance Benchmarks:** Manus’s innovative architecture has translated into strong performance on AI agent benchmarks. Notably, Manus achieved **state-of-the-art results on the GAIA benchmark** – a test designed by Meta, Hugging Face, and the AutoGPT team to evaluate real-world problem-solving by AI agents ([*Manus AI - China's Fully Autonomous AI Agent*](https://opencv.org/blog/manus-ai/#:~:text=3)) ([*Manus AI: The Best Autonomous AI Agent Redefining Automation and Productivity*](https://huggingface.co/blog/LLMhacker/manus-ai-best-ai-agent#:~:text=What%20is%20the%20GAIA%20Benchmark%3F)). Manus reportedly outperforms models like OpenAI’s GPT-4 on GAIA, especially on complex, multi-step tasks ([*Manus AI - China's Fully Autonomous AI Agent*](https://opencv.org/blog/manus-ai/#:~:text=GAIA%20Benchmark%20Results)) ([*Manus AI: The Best Autonomous AI Agent Redefining Automation and Productivity*](https://huggingface.co/blog/LLMhacker/manus-ai-best-ai-agent#:~:text=Manus%20AI%20has%20reportedly%20achieved,4%20and%20Microsoft%E2%80%99s%20AI%20systems)). In a breakdown across three difficulty levels of GAIA:
    -   *Level 1 (basic tasks):* Manus scored **86.5%**, versus 74.3% for OpenAI’s Deep Research baseline and \~68% for the previous state-of-the-art ([*Manus AI: Features, Architecture, Access, Early Issues & More \| DataCamp*](https://www.datacamp.com/blog/manus-ai#:~:text=The%20benchmark%20evaluates%20AI%20agents,across%20three%20difficulty%20levels)).

        \- *Level 2 (intermediate tasks):* Manus scored **70.1%**, slightly above OpenAI’s agent (69.1%) and well above prior best \~67% ([*Manus AI: Features, Architecture, Access, Early Issues & More \| DataCamp*](https://www.datacamp.com/blog/manus-ai#:~:text=1,for%20the%20previous%20best%20model)).

    -   *Level 3 (advanced tasks):* Manus led with **57.7%**, compared to 47.6% for OpenAI’s agent and \~42% previous best ([*Manus AI: Features, Architecture, Access, Early Issues & More \| DataCamp*](https://www.datacamp.com/blog/manus-ai#:~:text=2,for%20the%20previous%20best%20model)).

        These results suggest Manus is currently one of the most capable autonomous agents available ([*Manus AI: Features, Architecture, Access, Early Issues & More \| DataCamp*](https://www.datacamp.com/blog/manus-ai#:~:text=compared%20to%2047.6,for%20the%20previous%20best%20model)). Another source noted Manus’s overall GAIA performance is believed to exceed **65%**, surpassing the prior leader (H2O.ai’s agent at 65%) and far outstripping GPT-4’s plugin-enhanced performance (which was below 35%) ([*Manus AI: The Best Autonomous AI Agent Redefining Automation and Productivity*](https://huggingface.co/blog/LLMhacker/manus-ai-best-ai-agent#:~:text=Although%20exact%20scores%20are%20not,accuracy%20score)) ([*Manus AI: The Best Autonomous AI Agent Redefining Automation and Productivity*](https://huggingface.co/blog/LLMhacker/manus-ai-best-ai-agent#:~:text=Model%20GAIA%20Benchmark%20Accuracy%20%28,world)). While benchmarks are promising, Manus’s real-world effectiveness will ultimately be judged by its consistency and reliability in practical scenarios ([*Manus AI: Features, Architecture, Access, Early Issues & More \| DataCamp*](https://www.datacamp.com/blog/manus-ai#:~:text=models%20still%20struggle%20with%20the,step%20reasoning%20tasks)).

**Figure: Manus AI Architecture and Workflow**  
([*Introduction to LLM Agents \| NVIDIA Technical Blog*](https://developer.nvidia.com/blog/introduction-to-llm-agents/)) *General components of an LLM-powered agent (not specific to Manus). The agent core orchestrates planning, memory, and tool use to handle user requests autonomously (*[*Introduction to LLM Agents \| NVIDIA Technical Blog*](https://developer.nvidia.com/blog/introduction-to-llm-agents/#:~:text=an%20LLM,1)*). Manus follows this pattern with a central “brain” coordinating sub-agents (planning, coding, browsing, etc.) and using tools in a sandbox, all while maintaining memory of context and goals.*

### ANUS AI: Open-Source Autonomous Agent

In response to Manus’s closed beta release, the AI community quickly produced open-source implementations to democratize access to such autonomous agents. One notable project is **ANUS AI (Autonomous Networked Utility System)**, which was created as a Manus-inspired agent framework that is freely available. Despite the cheeky name, ANUS AI is a serious attempt to replicate and even extend the capabilities of Manus using open technologies ([*ANUS Autonomous Networked Utility System - TopTool*](https://www.toptool.app/en/product/anus-autonomous-networked-utility-system#:~:text=ANUS%20Autonomous%20Networked%20Utility%20System,dedicated%20to%20creating%20a)) (*TopTool - ANUS Autonomous Networked Utility System Review: Features, Pricing, Alternatives, Use Cases, and Details \| TopTool's Comprehensive Overview*).

ANUS AI’s design philosophy emphasizes openness, extensibility, and community collaboration. According to its documentation, *“Anus…is a powerful, flexible, and accessible open-source AI agent framework…offering unparalleled capabilities and ease of use.”* It aims to **“revolutionize task automation”** by empowering users to create AI agents that can handle complex tasks through natural language instructions, collaborate in multi-agent setups, interact with web services and documents, and process multimodal inputs across text, images, and audio ([*GitHub - nikmcfly/ANUS*](https://github.com/nikmcfly/ANUS#:~:text=Anus%20,capabilities%20and%20ease%20of%20use)) ([*GitHub - nikmcfly/ANUS*](https://github.com/nikmcfly/ANUS#:~:text=%2A%20Collaborate%20in%20multi,different%20domains%20and%20use%20cases)). In other words, ANUS is built to closely mirror the high-level feature set of Manus AI, while being completely open-source and adaptable.

Some **core features and architecture highlights** of ANUS AI include:

-   **Hybrid Single/Multi-Agent Architecture:** ANUS supports both running as a single agent and switching to a multi-agent mode when tasks demand it ([*GitHub - nikmcfly/ANUS*](https://github.com/nikmcfly/ANUS#:~:text=Advanced%20AI%20Agent%20Architecture)). This *hybrid architecture* allows it to start simple tasks as one agent and dynamically invoke additional helper agents if a task is complex enough to benefit from parallelism or specialization ([*GitHub - nikmcfly/ANUS*](https://github.com/nikmcfly/ANUS#:~:text=Advanced%20AI%20Agent%20Architecture)). This is similar to Manus’s orchestrator with sub-agents, and ANUS explicitly provides *“specialized agent roles”* out-of-the-box. For example, it defines preset roles like “Researcher,” “Coder,” “Planner,” etc., each with particular strengths ([*GitHub - nikmcfly/ANUS*](https://github.com/nikmcfly/ANUS#:~:text=Multi)). Developers can also create custom roles. These agents can communicate with each other through structured protocols, vote or reach consensus on decisions, and even resolve conflicts if different agents propose different solutions ([*GitHub - nikmcfly/ANUS*](https://github.com/nikmcfly/ANUS#:~:text=%2A%20Specialized%20Agent%20Roles%3A%20Pre,Sophisticated%20protocols%20for%20resolving%20disagreements)). Such collaboration mechanisms are a built-in part of ANUS’s multi-agent framework, reflecting advanced coordination strategies that one would need to implement for a group of AI agents working together.
-   **Dynamic Task Planning:** ANUS includes a sophisticated planning system to break down complex tasks into manageable steps ([*GitHub - nikmcfly/ANUS*](https://github.com/nikmcfly/ANUS#:~:text=,making%20processes)). The agent can take a high-level goal and decompose it, likely leveraging an internal planner module (possibly akin to LangChain’s planning or Semantic Kernel’s planner – which we’ll discuss later). This allows ANUS to handle multi-step problems methodically, ensuring it doesn’t skip crucial sub-tasks. It also features *adaptive resource allocation*, meaning it can manage computational resources or delegate tasks among agents depending on the complexity, to optimize performance ([*GitHub - nikmcfly/ANUS*](https://github.com/nikmcfly/ANUS#:~:text=,resources%20based%20on%20task%20requirements)).
-   **Comprehensive Tool Ecosystem:** Much like Manus, ANUS integrates a broad array of tools:
    -   **Web Interaction:** It has *full browser automation via Playwright*, enabling it to open pages, click buttons, fill forms, and scrape content just as a human user would ([*GitHub - nikmcfly/ANUS*](https://github.com/nikmcfly/ANUS#:~:text=%EF%B8%8F%20Comprehensive%20Tool%20Ecosystem)). This is critical for tasks like data mining, web research, or online transactions. It can handle authentication flows and form submissions, making it capable of, say, logging into websites or posting information.
    -   **Information Retrieval:** ANUS can call search engines, query Wikipedia, check news sources, and access specialized knowledge bases for facts ([*GitHub - nikmcfly/ANUS*](https://github.com/nikmcfly/ANUS#:~:text=)). This gives it up-to-date information access for research tasks.
    -   **Document Processing:** It can parse PDFs, read Office documents (Word, Excel, PowerPoint), perform OCR on images for text, and extract or transform data from these sources ([*GitHub - nikmcfly/ANUS*](https://github.com/nikmcfly/ANUS#:~:text=)). For an AI consulting agent, this means it could digest reports, analyze spreadsheets, or convert data formats without human help.
    -   **Code Execution:** ANUS provides a *secure Python execution sandbox* for running code, with support for multiple programming languages and package management ([*GitHub - nikmcfly/ANUS*](https://github.com/nikmcfly/ANUS#:~:text=)). Essentially, it replicates Manus’s ability to execute code, but likely within its own controlled environment (ensuring that user-provided or AI-written code can run safely). The output of code runs can be captured and fed back into the agent’s reasoning loop ([*GitHub - nikmcfly/ANUS*](https://github.com/nikmcfly/ANUS#:~:text=)). This allows automation of technical tasks like data analysis with Python libraries, or testing and debugging code.
    -   **Multimodal Processing:** It includes tools for image analysis/generation, audio processing (speech-to-text or text-to-speech, transcription), video analysis/summarization, and even interpreting charts/graphs ([*GitHub - nikmcfly/ANUS*](https://github.com/nikmcfly/ANUS#:~:text=)). These capabilities mean ANUS can handle a wide array of media – for example, summarizing the content of a video call, analyzing an image for a report, or generating a graphic.

        All these tools are organized as plugins or modules in ANUS’s framework, and developers can **extend it with custom plugins** easily ([*GitHub - nikmcfly/ANUS*](https://github.com/nikmcfly/ANUS#:~:text=Extensibility)). The design encourages adding new tools or integrating new AI models (with a plugin system and model adapter interfaces) ([*GitHub - nikmcfly/ANUS*](https://github.com/nikmcfly/ANUS#:~:text=Extensibility)) ([*GitHub - nikmcfly/ANUS*](https://github.com/nikmcfly/ANUS#:~:text=,by%20switching%20to%20alternative%20models)). This modability is ideal for an evolving system like SAMUS, where one might plug in domain-specific tools (e.g., for financial analysis or project management relevant to consulting).

-   **Memory and Explainability:** ANUS implements both short-term conversation memory and long-term memory storage for context ([*GitHub - nikmcfly/ANUS*](https://github.com/nikmcfly/ANUS#:~:text=,making%20processes)). This likely involves keeping histories of interactions and possibly vector databases for retrieval of past knowledge. The framework emphasizes *transparent operation* – it seeks to provide clear explanations of all agent actions and decisions to the user ([*GitHub - nikmcfly/ANUS*](https://github.com/nikmcfly/ANUS#:~:text=,Built%20for%20contributions%20and%20extensions)). This is important in a consulting scenario: the users (consultants or clients) may need to see why the AI made certain choices. ANUS’s logging and explanation features would ensure SAMUS can provide a trace or rationale for its autonomous steps, increasing trust.
-   **Performance and Benchmarks:** Being open-source, ANUS’s performance depends on what models and resources are plugged into it. The framework is model-agnostic, supporting OpenAI GPT-4, open models like Llama or Mistral, or local models ([*GitHub - nikmcfly/ANUS*](https://github.com/nikmcfly/ANUS#:~:text=Flexible%20Model%20Integration)). By default, it likely relies on whichever API keys or local models the user provides. While no specific benchmark scores are published for ANUS itself (since it’s more of a toolkit), the expectation is that it can approximate Manus’s performance if configured with powerful models. One advantage is that ANUS can run models locally for privacy or cost-saving, or switch models if one fails (it has a fallback mechanism) ([*GitHub - nikmcfly/ANUS*](https://github.com/nikmcfly/ANUS#:~:text=,by%20switching%20to%20alternative%20models)). This flexibility could be leveraged in SAMUS to ensure high availability (for instance, use GPT-4 via Azure OpenAI, but fall back to an open-source model if API quota is hit or for on-prem deployments).

In summary, ANUS AI provides a **blueprint for building a Manus-like agent with open tools**. It combines a **multi-agent orchestration**, a rich set of tools (web, code, docs), and modular components in a way that can be inspected and extended. These characteristics make it an excellent reference for SAMUS. Next, we will examine how the components of Manus/ANUS correspond to Semantic Kernel constructs, and how we can implement a similar system in C\#.

## Mapping Manus/ANUS Components to Semantic Kernel Equivalents

Microsoft’s **Semantic Kernel (SK)** is a development SDK that facilitates building AI-powered applications, including complex AI agents and even multi-agent systems. In fact, Semantic Kernel is explicitly designed to *“empower developers to build, orchestrate, and deploy AI agents and multi-agent systems”* with a modular approach (*microsoft/semantic-kernel: Integrate cutting-edge LLM ... - GitHub*). To design SAMUS, a Semantic Kernel based Manus/ANUS clone, we need to identify how key concepts from Manus/ANUS map onto Semantic Kernel’s features:

\- **Agents and Agent Roles:** In Manus/ANUS, an agent could be a specialized AI model or prompt persona (researcher, coder, planner, etc.) working on a task. In Semantic Kernel, the **Agent** concept is represented by the `Agent` class and related constructs in the experimental Agent Framework. SK allows defining multiple agents that can collaborate in a single conversation or process ([*Building Multi-Agent Systems with Multi-Models in Semantic Kernel*](https://arafattehsin.com/building-multi-agent-systems-with-multi-models-in-semantic-kernel-part-1/#:~:text=This%20framework%20is%20an%20experimental,facilitate%20agent%20interactions%20and%20collaboration)). Each agent in SK can be given its own instructions (persona/role) and even use different underlying models or skills. For example, SK’s `ChatCompletionAgent` or `OpenAIAssistantAgent` can encapsulate an LLM with certain behavior instructions ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=PortfolioManagerAgent%20%3D%20new%28%29%20,to%20other%20participant%20if%20needed)) ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=%2F%2F%2F%20Defining%20the%20Stock%20Analyzer,historical%20stock%20data%2C%20technical%20indicators)). **AgentGroupChat** is a Semantic Kernel class that enables multiple agents to converse and coordinate with each other in a shared context ([*Semantic Kernel Agent Framework \| Microsoft Learn*](https://learn.microsoft.com/en-us/semantic-kernel/frameworks/agent/#:~:text=Microsoft,Assistant%20API%20via%20the%20OpenAIAssistantAgent)). Therefore, **Manus’s multi-agent architecture (one orchestrator + sub-agents)** can be implemented by creating multiple `Agent` instances in SK (each with a role like “PlannerAgent”, “CoderAgent”, “WebResearchAgent”, etc.) and using `AgentGroupChat` to manage their interaction. The orchestrator role can either be an explicit agent or we can rely on a coordination strategy (see below). SK’s agent framework natively supports such collaboration patterns, with features like turn-taking strategies and channels for inter-agent communication ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=Step%202%3A%20Define%20Selection%20Strategy)) ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=%2F%2F%20Define%20selection%20strategy%20KernelFunctionSelectionStrategy,10%29%2C)).

-   **Planning and Task Decomposition:** Manus dynamically breaks tasks into sub-tasks and decides the next action through its iterative loop. In Semantic Kernel, there are a couple of equivalents:
    -   The **Planner**: Semantic Kernel provides planning APIs that use the LLM to compose a sequence of function calls (skills) to achieve a goal. For instance, SK’s `SequentialPlanner` or `ActionPlanner` can take a natural language goal and produce a step-by-step plan calling various functions (akin to how an agent decides on tools). This is comparable to Manus’s “plan” step in its loop. SAMUS could use an SK planner to interpret a high-level request and generate a plan that the agents then execute.

        \- **Function Calling with LLM**: Another approach (especially with the recent OpenAI function calling paradigm) is to let the model choose and invoke “tools” directly. SK supports this via the **FunctionChoice** mechanism. In practice, one can configure the SK kernel with `FunctionChoiceBehavior.Auto` so that when the model sees available functions (tools), it can request to use them autonomously ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=OpenAIPromptExecutionSettings%20openAIPromptExecutionSettings%20%3D%20new%28%29%20,Auto%28%29)). This mirrors Manus/ANUS where the AI decides which tool to use at each step. The *planning module* in SK’s agent core would correspond to giving the model knowledge of what functions are available and possibly a strategy for choosing which agent should act next.

    -   **Multi-agent coordination**: In a multi-agent SK scenario, planning might involve a higher-level agent assigning subtasks to others. Alternatively, SK’s **AgentGroupChat** supports a *selection strategy* – essentially a function to determine which agent speaks (acts) next ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=%2F%2F%20Define%20selection%20strategy%20KernelFunctionSelectionStrategy,10%29%2C)) ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=%2F%2F%20Define%20termination%20strategy%20KernelFunctionTerminationStrategy,HistoryReducer%20%3D%20new%20ChatHistoryTruncationReducer%281)). This can encode a simple round-robin or a more complex logic (even using an LLM to decide, as shown in Microsoft’s example where a prompt decides the next agent turn based on history ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=based%20on%20the%20most%20recent,one%20turn%20in%20a%20row)) ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=,nameof%28PortfolioManagerAgents%29%7D%7D%7D%27s%20turn))). By customizing this, we can ensure that, for example, after the Planner agent outlines steps, the Coder agent executes code, then the Research agent fetches data, etc., in a loop. Thus, **Manus’s orchestrator logic** can be implemented via SK’s planner plus agent selection strategies.
-   **Tool Use and Plugins:** Both Manus and ANUS heavily rely on tools (web browsers, shells, APIs, etc.) to accomplish tasks. In Semantic Kernel, tools are implemented as **skills** or **functions**. These can be **native C\# functions** (decorated with `[SKFunction]` or `[KernelFunction]` attributes) or semantic functions (prompt templates). For SAMUS, we will create a suite of SK functions that correspond to Manus/ANUS tools:
    -   For **web browsing**: We could integrate a headless browser library (e.g., Playwright for .NET or Selenium) wrapped in a function. For instance, a `BrowseUrl(string url)` function that returns the page text, or `ClickElement(selector)` etc. We might also use simpler web API calls for certain sites if a full browser isn’t needed.
    -   For **shell commands**: We can create a function that executes shell commands on the server (using `System.Diagnostics.Process` in C\# to run bash commands in a Linux container). This would be similar to ANUS’s secure Python sandbox, but since our whole SAMUS likely runs in a container or VM, we’ll ensure this function is sandboxed (more on security later). For safety, this function might restrict allowed commands or run them in a jailed environment.
    -   For **code execution**: We might allow the agent to run arbitrary code. One approach: implement a function `RunPython(code)` that takes a Python script (possibly generated by the LLM) and executes it, returning the output or error. This can be done by invoking a Python process in the background. Or use an embedded interpreter. Given the complexity, ensuring this is secure (time-limited, resource-limited) is crucial.

        \- For **information retrieval**: Functions to call search APIs (e.g., Bing Web Search or Google API), query Wikipedia (via an API or library), or fetch news (as in the SK example which used a NewsAPI service for the WebSurfer agent) ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=I%20am%20adding%202%20tools)) ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=1,registered%20with%20PortfolioManagement%20Agent)). These functions take a query and return summarized results.

    -   For **document parsing**: Functions using libraries like PDFSharp or OpenXML to read PDF/Word/Excel files and extract text or data. Perhaps a function like `ParsePDF(path)` that returns text, or `SummarizePDF(path)` that uses an LLM to summarize content.
    -   Any custom **business plugins** needed for an AI consulting agency (for example, accessing internal knowledge bases, CRMs, or project management tools) can also be added as SK functions.

        Semantic Kernel makes it straightforward to add these tools. We can load them via `kernel.ImportSkill(new MyCustomSkills(), "Tools")` or even dynamically with `Plugins.AddFromObject` as shown in SK documentation ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=%2F%2F%20Define%20function%2Ftools%20%5BKernelFunction%2C%20Description%28,%2F%2F%20implmentation%20here)). Once added, all these tools become available to the agents during their reasoning. In SK’s design, the list of functions (tools) can be included in the prompt context, so the model is aware of what actions it can perform. This aligns perfectly with Manus/ANUS where the agent must decide among its tools. With SK, SAMUS can have an expansive **plugin ecosystem** much like ANUS’s – using or skipping tools as needed.

-   **Memory (Context and Long-Term Memory):** In SK, memory is handled through two means:
    -   **Short-term context memory:** SK’s `ChatHistory` allows the system to maintain the conversation or reasoning history as context for the LLM. As agents communicate or perform steps, their dialogue (or state descriptions) can be added to a shared history. SK provides mechanisms to truncate or summarize this history when it gets too long (to cope with context window limits) ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=HistoryVariableName%20%3D%20,10%29%2C)). For example, the AgentGroupChat can use a `ChatHistoryTruncationReducer` to keep only the last N turns or a summary of earlier turns.
    -   **Long-term memory:** SK can connect to semantic memory stores (embeddings databases). An agent can store facts or documents with `kernel.Memory.SaveInformationAsync()` and later retrieve relevant info via embedding similarity. For SAMUS, we might use this to store user preferences, past project data, or any information that should persist across sessions. In ANUS/Manus terms, this is analogous to Manus remembering past user interactions or having a knowledge base. By leveraging something like Azure Cognitive Search or a vector DB via SK’s memory connectors, SAMUS could, for instance, recall that “last month we analyzed market X, use that data here” by searching the memory.
    -   Additionally, if needed, *persistent file-based memory* (like Manus uses) can be mimicked by simply writing to files or a database from SK functions. For example, an agent could log progress to a file that is then read later if the session restarts. This might not be needed if we use the above mechanisms, but it’s an option.

        **Mapping:** Manus’s memory and context tracking is thus mapped to **SK’s ChatHistory (short-term)** and **SK’s Semantic Memory or external DB (long-term)**. We will ensure SAMUS uses these to maintain continuity. Notably, SK doesn’t automatically retain memory between separate runs unless we program it to (e.g., by saving to a file or DB). In a continuous agent loop scenario, we’ll likely keep the SK kernel alive throughout the task so that the working memory stays in place. If the agent is paused or needs to resume later, we can serialize needed state to storage.

\- **Collaboration and Orchestration:** Manus had a single-user-facing agent that managed internal agents. ANUS explicitly has inter-agent communication protocols. In SK, the **AgentChat (AgentGroupChat)** handles the collaborative aspect. It essentially creates a multi-party chat session between agents (and optionally a user) ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=%2F%2F%20Initialize%20the%20multi,)). The developer can specify:

-   The *selection strategy* (which agent speaks when) – in SAMUS, this could implement a round-robin or a logical sequence (e.g., always Planner agent first, then others, etc.), or even let an LLM decide as in Microsoft’s portfolio manager example ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=based%20on%20the%20most%20recent,one%20turn%20in%20a%20row)).
    -   The *termination strategy* – a condition for when the agents should stop the loop ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=%2F%2F%20Define%20termination%20strategy%20KernelFunctionTerminationStrategy,HistoryReducer%20%3D%20new%20ChatHistoryTruncationReducer%281)). For example, after a certain number of iterations or when a certain agent outputs a result containing a specific flag like “TASK COMPLETE”. We can design SAMUS such that the Planner agent or main agent declares completion by outputting a token (like “done”) and set the termination strategy to watch for that ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=new%28GetTerminationStrategy%28%29%2C%20Kernel%29%20,1%29%2C%20MaximumIterations%20%3D%2010)).

        \- The *initial prompt or message* to kick off the conversation – likely the user’s request goes in as the first message to the group ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=chat.AddChatMessage%28new%20ChatMessageContent%28AuthorRole.User%2C%20,is%20Jan%2015th%202025)). Then agents start reacting according to their roles.

        Essentially, SK gives us a framework to implement the **“team meeting” of agents** that Manus’s architecture describes (with the orchestrator as a “manager” and sub-agents as “team members”). In SAMUS, we might not explicitly have a separate manager agent if we encode the logic via selection strategy; however, we could designate one agent as the leader that always coordinates others.

The following table summarizes the mapping between Manus/ANUS features and Semantic Kernel components for SAMUS:

| **Manus/ANUS Component**                               | **Semantic Kernel Equivalent**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
|--------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Multi-agent system (orchestrator + sub-agents)         | Multiple `Agent` instances with defined roles, managed via `AgentGroupChat` for collaboration ([*Building Multi-Agent Systems with Multi-Models in Semantic Kernel*](https://arafattehsin.com/building-multi-agent-systems-with-multi-models-in-semantic-kernel-part-1/#:~:text=This%20framework%20is%20an%20experimental,facilitate%20agent%20interactions%20and%20collaboration)) ([Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI                                                                                                                             |
| Iterative planning loop (analyze→plan→execute→observe) | SK Planner for goal decomposition; or agent prompts that incorporate reasoning and tool usage. Use of function calling (`FunctionChoiceBehavior.Auto`) to let the LLM choose and execute functions in each iteration ([Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI                                                                                                                                                                                                                                                                                            |
| Specialized agent roles (Researcher, Coder, etc.)      | Define multiple agents with different instructions/personas and possibly different models ([Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI                                                                                                                                                                                                                                                                                                                                                                                                                       |
| Tool integration (web browsing, code exec, etc.)       | Implement as SK native functions (plugins). E.g., `WebSearchSkill.Search`, `BrowserAutomation.Navigate`, `SystemCommands.RunBash`, `CodeRunner.RunPython`. These are added to the kernel and made available to agents ([Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI                                                                                                                                                                                                                                                                                           |
| Sandbox and security for tools                         | Deploy SAMUS within a locked-down Docker container (Linux) to replicate Manus’s VM sandbox. The `RunBash` or `RunPython` functions will execute within this container, ensuring file and process isolation. Additionally, we can enforce timeouts and resource limits in those functions (using subprocess controls in C\#) to avoid infinite loops or abuse.                                                                                                                                                                                                                                                                                          |
| Memory – short term (context)                          | SK’s `ChatHistory` for each agent (and shared history in AgentGroupChat). Use history truncation or summarization to manage context window ([Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI                                                                                                                                                                                                                                                                                                                                                                      |
| Memory – long term (knowledge base)                    | SK’s Semantic Memory (e.g., connect to an embedding store like Azure Cognitive Search, Pinecone, etc.) to store and retrieve information across sessions. Also, persistent storage (database or files) for any agent state that should persist (could be implemented via SK functions to read/write memory).                                                                                                                                                                                                                                                                                                                                           |
| Multi-modal inputs/outputs                             | Utilize SK’s ability to handle text primarily, but we can extend SAMUS with specialized tools for images/audio. For example, an OCR function for images (using Azure Computer Vision or Tesseract), or an image generation skill if needed. The results can be passed as base64 or URLs since SK itself is text-centric. Multimodal handling will largely be via plugins, not an out-of-the-box SK feature.                                                                                                                                                                                                                                            |
| Logging and explainable actions                        | Configure SAMUS to log every tool invocation and agent message (SK’s functions can log to console or files). We can also have agents “think aloud” by including a reasoning trace in their messages that is hidden from final user output. SK doesn’t force this, but we can design the prompt templates for agents to output an explanation before the actual answer, and then filter it out for the user if needed. This way, we have a record of *why* something was done (similar to ANUS’s transparent reasoning feature ([*GitHub - nikmcfly/ANUS*](https://github.com/nikmcfly/ANUS#:~:text=,Built%20for%20contributions%20and%20extensions))). |

By aligning these components, we ensure that SAMUS will carry the core functionalities of Manus and ANUS, but implemented through Semantic Kernel’s robust and flexible framework. Next, we delve into how to actually build the SAMUS system in C\#, step by step, using the SK Agent Framework and these mapped components.

## Building the SAMUS Multi-Agent System with Semantic Kernel (C\#)

### 1. Setting Up the Semantic Kernel Environment

To get started, we will use the Semantic Kernel SDK in C\#. Ensure you have the Semantic Kernel NuGet packages installed, including the core and the experimental Agents package. Specifically, we need **Microsoft.SemanticKernel** (core SDK) and *Microsoft.SemanticKernel.Agents. (Agent Framework)*\* – for example, *SemanticKernel.Agents.Core* which provides `ChatCompletionAgent` and `AgentGroupChat`, and *SemanticKernel.Agents.OpenAI* for integration with OpenAI or Azure OpenAI models ([*Semantic Kernel Agent Framework \| Microsoft Learn*](https://learn.microsoft.com/en-us/semantic-kernel/frameworks/agent/#:~:text=Package%20Description%20Microsoft,and%20%208%20classes)) ([*Semantic Kernel Agent Framework \| Microsoft Learn*](https://learn.microsoft.com/en-us/semantic-kernel/frameworks/agent/#:~:text=Microsoft,Assistant%20API%20via%20the%20OpenAIAssistantAgent)).

In code, you would initialize a Kernel, likely with an AI service:

```csharp
IKernel kernel = Kernel.Builder
    .Configure(c => c.AddOpenAITextCompletion("gpt-4", apiKey))
    .Build();
```

This sets up an OpenAI GPT-4 text completion service (for example). You could also configure Azure OpenAI or other model providers similarly. We might instantiate multiple kernels if using different models for different agents, but SK allows one kernel to manage multiple models by attaching them per function or using different `IAIService` instances. For simplicity, SAMUS can start with one powerful model (GPT-4) that handles all agents’ needs, and later we can optimize by assigning models per agent.

### 2. Defining Agent Roles (Specialized Agents)

With Semantic Kernel’s agent framework, we will create several agents to mirror Manus/ANUS sub-agents. For example, we may have:

-   **PlannerAgent** – coordinates the overall plan, breaks the task into sub-tasks.
-   **WebAgent** – handles web browsing and knowledge retrieval.
-   **CodeAgent** – responsible for writing/executing code when needed.
-   **AnalystAgent** – perhaps focuses on analyzing data and forming conclusions.
-   (We could start with 2-3 agents and expand as necessary.)

Each agent is essentially a configured prompt with its own instructions and a handle to the kernel (and thereby tools). In Semantic Kernel, we can define an agent like:

```csharp
var plannerAgent = new ChatCompletionAgent(kernel) {
    Name = "PlannerAgent",
    Instructions = "You are a planning agent. Decompose the user's request into actionable steps and decide which specialized agent (tool, skill) should do each step. You do not execute the steps yourself.",
};
```

**Example**  
You are an expert at data analysis. You have access to a data set with Order Id, Order Name, Customer Name, Product Name, Product Price, Order Total. Users are going to ask natural language questions about the data set. When a user ask is given to you, create a plan to answer the question. You have access to tools: a "UserIntentDiscovery" tool to discover user intent, a "DataSummarizer" tool to extract facts, dimension, filters, sort, aggregation, statistics, segmentation, correlation, and trend, a "WebSearch" tool to search the web, a "QueryPlanner" tool to write dataset query plan, a "CodeWriter" tool to write code, a "TerminalRunner" tool to run terminal commands, a "DataAnalyst" tool to take the context from all the other tools to generate a data story to fulfill the user's ask. With the user's ask, return a JSON string containing a numbered list of plan steps and tool calls.The user's ask is: "What was the first order over \$100"

```
{
  "plan": [
    {
      "step": 1,
      "description": "Use UserIntentDiscovery tool to clarify the user intent behind the question: 'What was the first order over $100?'",
      "tool": "UserIntentDiscovery"
    },
    {
      "step": 2,
      "description": "Use DataSummarizer tool to extract key components from the dataset relevant to the question: filter condition (Order Total > 100), and determine appropriate sort (by order date or inferred order of entry if date not available).",
      "tool": "DataSummarizer"
    },
    {
      "step": 3,
      "description": "Generate a query plan using the QueryPlanner tool to find the first order where Order Total > 100, sorted by the available ordering logic (e.g., Order Id or timestamp if present).",
      "tool": "QueryPlanner"
    },
    {
      "step": 4,
      "description": "Write the code to execute the query plan using the CodeWriter tool.",
      "tool": "CodeWriter"
    },
    {
      "step": 5,
      "description": "Run the code to get the result using the TerminalRunner tool.",
      "tool": "TerminalRunner"
    },
    {
      "step": 6,
      "description": "Use the DataAnalyst tool to present the answer in a human-readable data story format, including key details of the order found.",
      "tool": "DataAnalyst"
    }
  ]
}
```

Similarly, define a `webAgent` with instructions like *“You are a web researcher. You browse the web and answer questions with facts and sources. You only output results of web searches, and hand off when coding or planning is needed,”* and a `codeAgent` with something like *“You write and execute code to fulfill tasks. Provide code or results, and nothing else.”* These instructions come from our understanding of roles – they set the behavior boundaries for each agent ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=Name%20%3D%20nameof,Never%20give%20general%20guidelines)) ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=Name%20%3D%20nameof,%7D%2C%20Kernel)). In practice, we might iterate on these prompts to get the desired specialization. We also assign each agent a name and attach it to the same kernel (so they share the tool plugins added to the kernel). Optionally, we can use different models: SK’s `OpenAIAssistantAgent.CreateAsync` allows specifying a different model (like a code-focused model) for a given agent ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=%2F%2F%2F%20Defining%20the%20Stock%20Analyzer,historical%20stock%20data%2C%20technical%20indicators)) ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=and%20fundamental%20analysis%20to%20assess,%7D%2C%20Kernel)). For instance, CodeAgent might use `gpt-4-code` or another code model if available, whereas PlannerAgent uses regular GPT-4.

After creating agents, we combine them into an **AgentGroupChat**:

```csharp
var agentsChat = new AgentGroupChat(plannerAgent, webAgent, codeAgent) { ... };
```

We will configure the strategies next. At runtime, this group chat will allow the agents to talk to each other, simulate the collaborative workflow Manus has internally.

### 3. Creating and Registering Tools (SK Functions)

Now we implement the essential tools that the agents will use. In C\#, we can create a class `SamusTools` with methods for each action. For example:

```csharp
public class SamusTools {
    [SKFunction("Perform a web search and return top results summary")]
    public async Task<string> WebSearchAsync(string query) { ... }

    [SKFunction("Execute a bash shell command")]
    public string RunBash(string command) { ... }

    [SKFunction("Read a file from disk")]
    public string ReadFile(string path) { ... }

    [SKFunction("Write content to a file")]
    public string WriteFile(string path, string content) { ... }

    [SKFunction("Run a Python script and return output")]
    public string RunPython(string code) { ... }

    // ... etc.
}
```

Inside these, we use appropriate libraries:

-   For `WebSearchAsync`, call an external API (Bing, Google Custom Search, or an open API) and parse results to a summary. Or use a package like `System.Net.Http` to call an engine.
-   For `RunBash`, use `Process.Start` to run `bash -c "<command>"` and capture stdout/stderr. If SAMUS runs on Windows, you might use PowerShell or WSL, but we assume a Linux container for fidelity with Manus.
-   `RunPython` could write the code string to a temp file and then run `python <file>` similarly, capturing output. Ensure a timeout (e.g., if code hangs, kill it after X seconds).
-   We can also add specialized ones: e.g., `BrowseUrl` that uses a headless browser (this is more complex: possibly use PlaywrightSharp to launch a browser and get page content). This might be asynchronous.
-   If needed, add `AnalyzeData` or others for domain tasks.

Once these methods are written, we register them with the kernel:

```csharp
kernel.ImportSkill(new SamusTools(), "Tools");
```

This makes each method available as an SK function under the `Tools.` skill collection. The agents (which use the same kernel) can now call these by name.

We should also set the kernel’s function calling mode to automatic so that our LLM can decide to invoke them. As seen in a SK example, we adjust the prompt or the AI service settings:

```csharp
var openAISettings = new OpenAIRequestSettings() {
    FunctionCall = FunctionCall.Auto
};
```

And pass that to the agent (the earlier code snippet [26†L296-L303] shows `FunctionChoiceBehavior.Auto()` which is a similar concept). In practice, the latest SK might use the OpenAI function calling JSON; anyway, the idea is the LLM can respond with a function call like `{"function": "WebSearchAsync", "arguments": {"query": "something"}}`, and SK will execute `SamusTools.WebSearchAsync` and feed the result back to the conversation.

### 4. Orchestrating Multi-Agent Collaboration

With agents and tools defined, we configure how the agents interact in the group chat:

-   **Selection Strategy:** We define a function or rule for which agent gets to speak (act) at each step. A simple strategy is round-robin: Planner -\> Web -\> Code -\> (repeat). Alternatively, always let Planner start, then based on context, let a specific agent take over. Microsoft’s sample implemented the strategy using a prompt function that takes the last speaker and returns the next agent’s name ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=based%20on%20the%20most%20recent,one%20turn%20in%20a%20row)) ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=,nameof%28PortfolioManagerAgents%29%7D%7D%7D%27s%20turn)). We could do something similar: e.g., after Planner gives a plan, always let an executor agent handle the first step, then maybe loop back. Initially, round-robin might be fine to ensure everyone gets a turn. SK provides `KernelFunctionSelectionStrategy` where you provide a function (could be a prompt or code) to pick the next agent ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=%2F%2F%20Define%20selection%20strategy%20KernelFunctionSelectionStrategy,10%29%2C)).

\- **Termination Strategy:** We need a condition to stop the loop. Perhaps we decide that when the PlannerAgent says the plan is fully done or one of the agents outputs a special token (like “” or simply mentions “done”), we stop. We can implement a `KernelFunctionTerminationStrategy` with a result parser that scans for a keyword “done” in the content ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=new%28GetTerminationStrategy%28%29%2C%20Kernel%29%20,1%29%2C%20MaximumIterations%20%3D%2010)). We also set a max iterations safety (e.g., no more than 10-20 cycles to avoid infinite loops) ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=result.GetValue%3Cstring%3E%28%29%3F.Contains%28,1%29%2C%20MaximumIterations%20%3D%2010%2C)). This prevents the kind of looping issue that early Manus testers reported ([*Manus AI: Features, Architecture, Access, Early Issues & More \| DataCamp*](https://www.datacamp.com/blog/manus-ai#:~:text=For%20instance%2C%20early%20testers%20have,pointed%20out%20several%20issues)) (Manus sometimes got stuck repeating steps). In SAMUS, if it doesn’t converge by, say, 15 iterations, we break and return control to the user for review.

After setting up these strategies, we attach them to the AgentGroupChat:

```csharp
agentsChat.ExecutionSettings.SelectionStrategy = selectionStrategy;
agentsChat.ExecutionSettings.TerminationStrategy = terminationStrategy;
```

Now we initiate the process by injecting the user’s request as the first message and running the chat loop:

```csharp
agentsChat.AddUserMessage(userGoal);
await foreach (var message in agentsChat.RunAsync())
{
    Console.WriteLine($"{message.AuthorName}: {message.Content}");
}
```

This will asynchronously go through agent turns. For example, the PlannerAgent might receive the user goal and output a plan of steps. Next, the selection strategy picks perhaps the WebAgent to gather info; the WebAgent’s turn triggers, it may decide to call the WebSearch tool, after which SK inserts the function result, then WebAgent outputs some findings, and so on. The CodeAgent might chime in when code needs to run, using the `RunPython` function. Finally, once the tasks are done (perhaps the PlannerAgent sees all steps completed), it might output the final answer or summary with “done”. The termination triggers and we break out, returning the result to the user (which could be the final message content or a compiled report).

Throughout this process, the **Semantic Kernel ensures that each agent has access to the shared context and tools**. The agents essentially “speak” to each other in natural language (augmented by the function call executions) to collaboratively solve the problem, exactly as Manus’s internal modules would – but here we, as developers, have orchestrated it via SK’s APIs.

### 5. Ensuring Cloud-Readiness and Sandboxing

Since SAMUS is intended to run in the cloud, there are a few considerations:

-   **Concurrency and State:** If multiple users (consultants or clients) will use SAMUS, we need to handle concurrent sessions. We wouldn’t want different user sessions to mix contexts. A simple way is to instantiate a separate Kernel (with its agents and skills) per session or user request. This way, each one has isolated memory and history. This could be managed in a web API where each incoming request creates a SAMUS instance that lives long enough to finish the task.
-   **Sandboxing Tools:** We must confine the effects of tools like `RunBash` and `RunPython`. The best approach is to run SAMUS itself in a container with limited permissions. For example, if deployed on Azure, use a Linux Docker container that has no access to sensitive host resources, and doesn’t mount any host volumes except perhaps a temp folder. Within that container, even if `RunBash("rm -rf /")` is executed mistakenly, it would only affect the container’s filesystem (which can be ephemeral). We should also ensure that any secrets (API keys, etc.) are kept safe (not exposed to the AI unless needed).
-   **Error Handling:** The tools should catch exceptions (e.g., a Python script error) and return them as output to the agent, rather than crashing the whole system. The agent can then decide to handle the error (maybe the CodeAgent will adjust code if an error is in output). This is akin to how Manus observes errors and tries again ([*In-depth technical investigation into the Manus AI agent, focusing on its architecture, tool orchestration, and autonomous capabilities. · GitHub*](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=,to%20iteratively%20write%2C%20execute%2C%20and)). We should implement try-catch in our SK functions and possibly truncate or sanitize error messages to avoid confusing the LLM with superfluous data.
-   **Scalability:** SK itself is just an in-process library, so to handle heavy workloads, scaling out means running more instances of SAMUS (containers or processes). We might not need multi-threading within one agent loop (the AgentGroupChat loop is sequential turn-based by design). But we can allow parallelism in certain tool functions (like downloading multiple pages concurrently within a web search function, etc.).

By the end of these steps, we have a functional multi-agent system built on Semantic Kernel, where each agent can use tools and collaborate to solve tasks in a manner conceptually similar to Manus/ANUS.

## Deployment Strategies for SAMUS in the Cloud

Deploying an autonomous multi-agent system like SAMUS in a cloud environment requires careful planning for reliability, security, and scalability. Here are several approaches and best practices:

-   **Containerization (Docker):** The simplest deployment unit for SAMUS is a Docker container containing the .NET runtime and the SAMUS application. Containerization ensures environment consistency (we can include all necessary libraries, like headless browser or Python interpreter, in the image) and encapsulates the Linux sandbox that SAMUS needs. The Docker image should use a lightweight base (e.g., Alpine or Debian-slim) and include dependencies for any tools (for instance, Playwright dependencies for browser automation, Python for code exec, etc.). By containerizing, we inherently sandbox the OS-level commands and file writes to within the container. We can also set resource limits on the container (CPU/RAM) to prevent any runaway process from overwhelming the host.
-   **Azure App Service or Container Instances:** Azure App Service can directly run Docker containers or a standalone .NET app. This is a PaaS approach – easy to deploy and manage, with auto-scaling options. If using App Service, we should enable the *Web App for Containers* feature, deploy our container, and use application settings for configuration (like injecting API keys, etc.). Azure Container Instances (ACI) is another option to run containers on demand without managing VMs; it might be suitable for event-driven usage (spawn a container when a task comes, then shut down). However, for an interactive agent that might maintain state, ACI could be too transient unless orchestrated by an external manager.
-   **Azure Functions (Serverless) with Durable Functions:** If we want SAMUS to execute as serverless functions, we face the challenge that a single function invocation is short-lived (max \~10 minutes by default) and stateless. However, Microsoft’s Durable Functions extension allows for long-running workflows with state. We could structure SAMUS as a *Durable Orchestration*: one function orchestrator manages a conversation state, and different activities represent agent actions. For example, the orchestrator could loop, calling an activity function that invokes the SK Agent step and yields the next state, then continues until a condition is met (this is advanced and essentially re-implementing a bit of what AgentGroupChat does, but in a serverless-friendly way). Durable Functions would automatically checkpoint state so even if the process reloads, it resumes from last checkpoint – useful if tasks take a long time or need to survive instance restarts. The benefit of Azure Functions is automatic scaling: if the consulting agency occasionally needs to spin up 50 concurrent agent sessions, it can scale out without pre-provisioning servers. One must ensure the Functions plan has enough resources (and maybe use the Premium plan for longer execution time and network access, since sandbox restrictions might apply on the Consumption plan).
-   **Kubernetes (AKS) or Container Orchestration:** For maximum control and scalability, deploying SAMUS on Azure Kubernetes Service (AKS) is a strong option. We can run multiple replicas of the SAMUS service, containerized as discussed. Using Kubernetes allows:
    -   Easy horizontal scaling (launch more pods when load increases).
    -   Isolation of sessions (each user session could be handled by a specific pod if needed, or simply share pods if stateless between requests).
    -   Integration with other services (maybe SAMUS pods connect to a Redis cache for shared memory, or a database for logging).
    -   Rolling updates with minimal downtime – important as we refine SAMUS.

        In AKS, we can also attach persistent volumes if SAMUS needs to persist data, and we can use Kubernetes secrets to store API keys for models and tools.

-   **Azure AI Integration:** Since Semantic Kernel often uses Azure OpenAI for the model, we should deploy SAMUS in the same region as the Azure OpenAI resource for low latency. Also, consider using Azure’s Managed Identity or Key Vault to supply the OpenAI API key securely to SAMUS (rather than hardcoding it).
-   **Monitoring and Logging:** In a production cloud deployment, incorporate Azure Monitor or Application Insights. SAMUS should log important events (e.g., each agent step, any errors) to a centralized log. This is crucial for a consulting agency to audit what the AI is doing. If something goes wrong or results are strange, logs will help trace agent decisions. We can use the built-in .NET logging frameworks and wire them to Application Insights.
-   **Security Hardening:** Beyond sandboxing, ensure the container or app has minimal privileges. For example, run as a non-root user inside the container. Limit outbound network access if possible (perhaps only allow certain APIs or domains if we want to prevent the agent from accessing the entire internet, though that limits functionality). Use Azure’s firewall or VNet integration for stricter control if needed. Also, if the AI is allowed to execute code, be mindful of supply chain – e.g., if it can pip install packages, that could be abused. Maybe restrict or pre-install needed packages.
-   **User Interface / Integration:** SAMUS can be exposed as a web service (e.g., a Web API that accepts a task description and returns results or a URL to results). For a consulting agency, one might build a web front-end where consultants input requests and get outputs (like reports or analysis) from SAMUS. If deploying on App Service or AKS, exposing an HTTP endpoint is straightforward. If using Functions, an HTTP trigger function can start the durable orchestration and then check status. Depending on how interactive the usage is (is it one-shot tasks, or a conversational back-and-forth?), you may also consider a persistent WebSocket or a SignalR hub to stream intermediate results (like how Manus can update the user as it works).

In summary, a likely deployment for a consulting agency could be: **Dockerize SAMUS -\> Deploy on Azure Kubernetes Service** behind an API. This gives the agency flexibility to scale with workload and to encapsulate the system in a robust, monitored environment. For less intensive use, an Azure App Service with container could suffice. In any case, cloud deployment should preserve the **Linux sandbox** (by virtue of running on Linux containers or VMs) to replicate Manus’s safe execution model.

## Enhancements and Innovations for Consulting Use Cases

SAMUS as described would closely follow Manus and ANUS in functionality, but there are several ways to improve upon the original models, especially tailored to consulting scenarios:

\- **Improved Reliability and Loop Control:** Manus in its early version had issues with getting stuck in loops or failing to converge on a solution in some cases ([*Manus AI: Features, Architecture, Access, Early Issues & More \| DataCamp*](https://www.datacamp.com/blog/manus-ai#:~:text=For%20instance%2C%20early%20testers%20have,pointed%20out%20several%20issues)) ([*Manus AI: Features, Architecture, Access, Early Issues & More \| DataCamp*](https://www.datacamp.com/blog/manus-ai#:~:text=,ability%20to%20execute%20commands%2C%20retrieve)). SAMUS can address this by implementing robust loop termination checks and fallbacks. For example, if the agents loop without making progress (same step repeating) more than 2-3 times, SAMUS could recognize this and escalate – perhaps by having a “meta-agent” or simply logic to break out and return a partial result with a note to the user. This ensures the system doesn’t burn resources endlessly. We can also incorporate **time limits** for tasks and give the user an option to extend if needed, similar to how some human processes have timeboxing.

-   **Advanced Model Switching / Ensemble:** Manus dynamically used multiple models; SAMUS could extend this by automatically choosing among available models based on the task or even running tasks in parallel through different models and comparing results. For instance, for a critical analysis, SAMUS could get answers from both GPT-4 and an open-source model and either pick the best or even merge insights (agent consensus voting, akin to an ensemble of experts). This could improve accuracy and mitigate single-model biases. With SK, this can be done by instantiating multiple kernels or using different AI services for different functions.
-   **Domain-Specific Knowledge Integration:** An AI consulting agent would benefit from having knowledge of the specific domain or client context. We can integrate SAMUS with **organizational data sources**. For example, connect to a company’s databases, wikis, or past reports so that the agent can pull in proprietary insights (with permission). Using SK’s memory or custom skills, SAMUS could query these internal sources. This goes beyond Manus’s generic knowledge by tailoring the agent to the consulting agency’s needs (essentially creating a **knowledge graph** or **RAG – Retrieval-Augmented Generation** component for SAMUS). Ensuring confidentiality and access control here is key, of course.
-   **Enhanced Toolset for Consulting**: We could add plugins for things like:
    -   **Spreadsheet analysis** – e.g., a function to run Excel formulas or use Python pandas for data analysis.
    -   **Slide generation** – maybe integrate with an API that can create PowerPoint slides or use LaTeX for PDFs, so the agent can deliver not just raw results but polished deliverables (reports, charts).
    -   **Email or Report Drafting** – a skill to format the final output into an email or document template that a consultant might send to a client.
    -   **Project management** – if a consultant asks the agent to schedule meetings or set reminders, integrate with calendar or task APIs.

        These plugins extend SAMUS beyond what Manus originally did, focusing it for consulting operations (which often involve preparing documents, insights, and coordinating tasks).

-   **Human-AI Collaboration Features:** In consulting, it’s unlikely the AI will be allowed to just run fully unchecked. SAMUS can incorporate **human-in-the-loop checkpoints**. For example, after SAMUS compiles a plan, it could ask the user “Proceed with this plan? [Y/N]”. The user (consultant) can then approve or tweak the plan. Similarly, if SAMUS wants to execute a potentially sensitive action (like sending an email or making a purchase), it should request confirmation. This can be done by having a mode where SAMUS pauses and surfaces a question to the UI, which then the human answers and resumes the agent. This ensures control and builds trust in the system.
-   **Transparency and Reporting:** While ANUS emphasizes transparent reasoning (likely printing out its chain-of-thought), for a client deliverable we might not want to show raw reasoning, but we *do* want to log it. SAMUS could maintain a **detailed log or even a “journal” of what it did and why**, which can be packaged as an appendix in the result. For instance, after completing a task, SAMUS could provide the consultant with: “Here’s the final answer, and here is a log of all actions taken (with timestamps and tool outputs).” This can help the consultant verify the work or troubleshoot if something looks off. It’s also a learning tool to improve SAMUS’s prompts if needed by analyzing where it went wrong.
-   **Scaling and Parallelism:** We mentioned SAMUS’s multi-agent nature allows parallel work. We could push this further – for example, if a task involves analyzing 100 PDFs, instead of doing it one-by-one in a single agent loop, SAMUS could spawn multiple analysis agents in parallel threads or distribute among multiple containers (map-reduce style for AI). This would use more resources but finish much faster, which might be valuable for tight deadlines.
-   **Continuous Learning and Tuning:** Over time, the consulting agency can fine-tune SAMUS on its data. Using Semantic Kernel’s ability to incorporate ML models, one could train custom models for frequent tasks (maybe a smaller model fine-tuned on writing consulting reports). SAMUS can then use those as tools (e.g., a fine-tuned model for summarizing financial statements). Additionally, feedback from consultants on SAMUS outputs can be fed into improving prompts or ranking the agent’s answers (reinforcement learning from human feedback concept). Essentially, treat SAMUS as a living system that improves with each engagement.
-   **Better UI/UX for Results:** If SAMUS is to be client-facing indirectly (through consultants), we could integrate it with a nice interface. For example, an interactive notebook or a dashboard where the agent’s findings are updated in real-time (like watching Manus’s “computer screen” in the Manus demo which shows what it’s doing ([*Introducing Manus: The general AI agent — WorkOS*](https://workos.com/blog/introducing-manus-the-general-ai-agent#:~:text=complex%20workflows,agent))). This can increase confidence as the consultant can literally see SAMUS “think” (e.g., “Searching for latest market data…”, “Coding a script to analyze trends…”). Even simple console or log streaming could be wrapped in a web UI.
-   **Safety and Ethics:** For consulting use, one must ensure the agent adheres to compliance requirements. We might add an **ethical guardrail agent** or filters. For example, before executing any shell command or making an external call, run the requested action through a policy filter (maybe a list of disallowed actions or a moderate check for content to not leak confidential info). Microsoft’s Responsible AI services or Azure OpenAI’s content filtering can be applied to the agent’s outputs. This reduces risk of the AI doing something that violates company policy or laws (especially if it has the power to act autonomously).

Finally, we note that while SAMUS aims to replicate Manus and ANUS, it stands on the shoulders of these giants with the advantage of Semantic Kernel’s robust infrastructure and the flexibility to integrate with Microsoft’s ecosystem (Azure services, .NET libraries, etc.). This synergy can produce a powerful AI agent tailored for consulting workflows – one that not only matches the original agents in autonomy and intelligence, but also exceeds them in **practical usability, safety, and integration** within a business context.

## Conclusion

**SAMUS** is envisioned as a fusion of Manus’s groundbreaking autonomous agent capabilities with the openness and extensibility of ANUS, implemented on the solid foundation of Microsoft’s Semantic Kernel. By deeply understanding the architectures of Manus and ANUS – from their multi-agent orchestration, planning loops, tool use, to their performance characteristics – we mapped out a path to recreate these features in C\# with SK’s agents, planners, memory, and plugins. We designed SAMUS to incorporate core features like Linux sandboxed execution, web browsing automation, shell and code execution, and collaborative agents working in concert, all while running securely and scalably in a cloud environment.

This report has detailed how to build such a system step-by-step, and proposed deployment strategies using modern cloud platforms (Docker, Azure) to ensure that SAMUS can operate reliably in an enterprise setting like an AI consulting agency. We also discussed enhancements that can make SAMUS even more powerful and suitable for real-world use – including improved reliability controls, integration with domain-specific knowledge, human oversight, and ongoing learning.

In essence, SAMUS will not only *clone* what Manus and ANUS have achieved, but also *advance* the state-of-the-art for AI agents in professional services. With careful implementation and testing, SAMUS could become a valuable autonomous assistant for consultants – handling tedious multi-step research and analysis tasks, generating insights and reports, and allowing human experts to focus on higher-level decision-making. The combination of Semantic Kernel’s agent framework and the lessons from Manus/ANUS provides a blueprint to realize this vision of a cloud-native, enterprise-ready AI agent.

**Sources:** The design and recommendations above are backed by information from Manus AI’s public descriptions and analyses ([*Manus AI: Features, Architecture, Access, Early Issues & More \| DataCamp*](https://www.datacamp.com/blog/manus-ai#:~:text=Multi)) ([*In-depth technical investigation into the Manus AI agent, focusing on its architecture, tool orchestration, and autonomous capabilities. · GitHub*](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=%28Manus%E5%9C%A8%E7%B4%85%E4%BB%80%E9%BA%BC%EF%BC%9F%E5%A4%96%E5%AA%92%E8%A9%95%E6%B8%AC%E8%A8%82%E9%A4%90%E3%80%81%E8%A8%82%E4%BD%8D%E3%80%81%E8%A8%82%E7%A5%A8%E2%8B%AF%E9%83%BD%E7%A2%B0%E5%A3%81%EF%BC%9A%E5%AE%83%E6%98%AF%E4%B8%AD%E5%9C%8B%E7%AC%AC%E4%BA%8C%E5%80%8BDeepSeek%E6%99%82%E5%88%BB%EF%BC%9F%29.%20A%20high,one%20agent%20writing%20the%20code)), the ANUS AI open-source documentation ([*GitHub - nikmcfly/ANUS*](https://github.com/nikmcfly/ANUS#:~:text=Anus%20,capabilities%20and%20ease%20of%20use)) ([*GitHub - nikmcfly/ANUS*](https://github.com/nikmcfly/ANUS#:~:text=%EF%B8%8F%20Comprehensive%20Tool%20Ecosystem)), and official Semantic Kernel resources and examples ([*Building Multi-Agent Systems with Multi-Models in Semantic Kernel*](https://arafattehsin.com/building-multi-agent-systems-with-multi-models-in-semantic-kernel-part-1/#:~:text=This%20framework%20is%20an%20experimental,facilitate%20agent%20interactions%20and%20collaboration)) ([*Guest Blog: Step-by-Step Guide to Building a Portfolio Manager: A Multi-Agent System with Microsoft Semantic Kernel and Azure OpenAI \| Semantic Kernel*](https://devblogs.microsoft.com/semantic-kernel/guest-blog-step-by-step-guide-to-building-a-portfolio-manager-a-multi-agent-system-with-microsoft-semantic-kernel-and-azure-openai/#:~:text=1,registered%20with%20PortfolioManagement%20Agent)), as cited throughout the report. With this foundation, SAMUS is well positioned to emulate and build upon the “agentic AI” revolution that Manus has sparked ([*Manus AI: Features, Architecture, Access, Early Issues & More \| DataCamp*](https://www.datacamp.com/blog/manus-ai#:~:text=suddenly%20switch%20to%20Manus,or%20proprietary%20models%20to%20function)), bringing that power into the hands of businesses in a safe and effective way.
